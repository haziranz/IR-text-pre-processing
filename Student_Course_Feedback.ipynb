{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Student Course Feedback.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMYcD1M7ePNO3fmy0B+6ASJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haziranz/IR-text-pre-processing/blob/main/Student_Course_Feedback.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKLcwEYMniZE"
      },
      "source": [
        "# open data file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vL4mn3eoPMbp"
      },
      "source": [
        "path = \"/content/Student Course Feedback.txt\"\n",
        "file1 = open(path, \"r\")\n",
        "text = file1.read()\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rg_NyYoqnwQs"
      },
      "source": [
        "# remove html tag"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VT80oPv26zA"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "raw = BeautifulSoup(text, 'html.parser').get_text()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F35BPIeo3Muw"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnKNGSkCn4gZ"
      },
      "source": [
        "# tokenize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bnhf6iiI3AxY"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "tokens = word_tokenize(raw)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bB6O1c5r3UwH",
        "outputId": "26a4ef59-933c-4eba-bdc0-c81584928ec2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(list(iter(tokens)))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Honestly', 'last', 'seven', 'lectures', 'are', 'good', '.', 'Lectures', 'are', 'understandable', '.', 'Lecture', 'slides', 'are', 'very', 'useful', 'to', 'self-study', 'also', '.', 'The', 'given', 'opportunity', 'to', 'ask', 'questions', 'from', 'the', 'lecturer', 'is', 'appreciative', '.', '``', 'Good', ':', ')', 'please', 'do', 'recap', 'at', 'class', 'starting', 'it', \"'s\", 'better', 'for', 'us', '.', 'sometimes', 'teaching', 'speed', 'is', 'very', 'high', '.', 'Thanks', '!', ':', ')', '``', 'The', 'lectures', 'are', 'good..but', 'a', 'bit', 'speed.A', 'in', 'class', 'working', 'activity', 'is', 'a', 'must', 'one.So', 'please', 'take', 'another', 'hour', 'in', 'thursdays', 'madame.', \"''\", 'We', 'can', 'hear', 'your', 'voice', 'clearly', 'and', 'can', 'understand', 'the', 'things', 'you', 'teach', '.', 'Presentation', 'slides', 'also', 'good', 'source', 'to', 'refer', '.', 'lf', 'you', 'can', 'do', 'more', 'example', 'questions', 'within', 'the', 'classroom', 'and', 'it', 'will', 'help', 'us', 'to', 'understand', 'the', 'principles', 'well.', \"''\", 'Lectures', 'was', 'well', 'structured', 'and', 'well', 'organized', '.', 'It', 'was', 'easy', 'to', 'understand', '.', 'Lecture', 'slides', 'and', 'labs', 'were', 'also', 'well', 'organized', '.', 'Lectures', 'were', 'good', '.', 'understandable', '.', 'The', 'lecture', 'slides', 'were', 'well', 'organized', 'and', 'the', 'examples', 'done', 'in', 'the', 'class', 'helped', 'a', 'lot', 'to', 'learn', 'this', 'new', 'language', 'and', 'also', 'the', 'principles', 'of', 'OOP', '.', 'Motivated', 'to', 'well', '.', 'Would', 'have', 'been', 'better', 'if', 'we', 'discussed', 'more', 'about', 'the', 'solutions', 'of', 'coding', 'exercisers', '.', 'I', 'think', 'i', 'learned', 'a', 'lot', 'from', 'the', 'codes', 'you', 'write', 'in', 'the', 'board', '.', 'When', 'i', 'compare', 'my', 'codes', 'with', 'yours', 'i', 'can', 'learn', 'about', 'my', 'mistakes', 'and', 'good', 'coding', 'practices', 'that', 'i', 'should', 'follow', '.', 'There', 'fore', 'i', 'think', 'it', 'would', 'be', 'great', 'if', 'we', 'can', 'discuss', 'more', 'examples', 'in', 'the', 'class', '.', 'madam', 'explained', 'the', 'oop', 'concepts', 'clearly', 'with', 'examples.lectures', 'were', 'interesting.we', 'want', 'more', 'scenario', 'examples', 'and', 'answers', 'with', 'explanations', 'in', 'future', '.', 'I', 'satisfy', 'about', 'first', '7', 'lectures', '.', 'That', 'way', 'of', 'teaching', 'is', 'really', 'good', 'for', 'coming', 'lectures', 'too', '.', 'lectuers', 'are', 'very', 'good', '.', 'take', 'good', 'effort', 'to', 'make', 'undersatand', 'every', 'student', 'in', 'the', 'room', '.', 'very', 'helpfull', '.', 'I', 'was', 'able', 'to', 'obtain', 'a', 'clear', 'picture', 'about', 'OOP', 'and', 'its', 'concepts', '.', '``', 'lecture', 'slides', ',', 'explanations', 'were', 'very', 'clear', '.', 'it', \"'s\", 'very', 'good', 'to', 'letting', 'ask', 'questions', 'and', 'explain', 'again', 'with', 'suitable', 'examples', '.', 'sometimes', ',', 'some', 'codes', 'on', 'white', 'board', 'were', 'unclear', 'at', 'the', 'back', '.', 'overall', 'very', 'good', '!', '!', '!', \"''\", 'The', 'lectures', 'were', 'good', 'and', 'clear', '.', 'And', 'they', 'were', \"n't\", 'too', 'fast', '.', 'Writing', 'code', 'was', 'somewhat', 'confusing', 'because', 'I', 'did', \"n't\", 'know', 'java', 'before', '.', 'Actually', 'teaching', 'is', 'very', 'good', 'and', 'can', 'understand', 'easily', 'the', 'concepts', 'by', 'examples', 'which', 'are', 'given', 'in', 'the', 'class.it', 'will', 'be', 'more', 'helpful', 'if', 'provide', 'solved', 'questions', 'as', 'well', '!', '.', 'thankyou']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4nRf1RC4BCF",
        "outputId": "fc268cf1-2d72-435f-8d5c-6f818ec840bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from gensim.utils import tokenize\n",
        "\n",
        "print(list(iter(list(tokenize(raw)))))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Honestly', 'last', 'seven', 'lectures', 'are', 'good', 'Lectures', 'are', 'understandable', 'Lecture', 'slides', 'are', 'very', 'useful', 'to', 'self', 'study', 'also', 'The', 'given', 'opportunity', 'to', 'ask', 'questions', 'from', 'the', 'lecturer', 'is', 'appreciative', 'Good', 'please', 'do', 'recap', 'at', 'class', 'starting', 'it', 's', 'better', 'for', 'us', 'sometimes', 'teaching', 'speed', 'is', 'very', 'high', 'Thanks', 'The', 'lectures', 'are', 'good', 'but', 'a', 'bit', 'speed', 'A', 'in', 'class', 'working', 'activity', 'is', 'a', 'must', 'one', 'So', 'please', 'take', 'another', 'hour', 'in', 'thursdays', 'madame', 'We', 'can', 'hear', 'your', 'voice', 'clearly', 'and', 'can', 'understand', 'the', 'things', 'you', 'teach', 'Presentation', 'slides', 'also', 'good', 'source', 'to', 'refer', 'lf', 'you', 'can', 'do', 'more', 'example', 'questions', 'within', 'the', 'classroom', 'and', 'it', 'will', 'help', 'us', 'to', 'understand', 'the', 'principles', 'well', 'Lectures', 'was', 'well', 'structured', 'and', 'well', 'organized', 'It', 'was', 'easy', 'to', 'understand', 'Lecture', 'slides', 'and', 'labs', 'were', 'also', 'well', 'organized', 'Lectures', 'were', 'good', 'understandable', 'The', 'lecture', 'slides', 'were', 'well', 'organized', 'and', 'the', 'examples', 'done', 'in', 'the', 'class', 'helped', 'a', 'lot', 'to', 'learn', 'this', 'new', 'language', 'and', 'also', 'the', 'principles', 'of', 'OOP', 'Motivated', 'to', 'well', 'Would', 'have', 'been', 'better', 'if', 'we', 'discussed', 'more', 'about', 'the', 'solutions', 'of', 'coding', 'exercisers', 'I', 'think', 'i', 'learned', 'a', 'lot', 'from', 'the', 'codes', 'you', 'write', 'in', 'the', 'board', 'When', 'i', 'compare', 'my', 'codes', 'with', 'yours', 'i', 'can', 'learn', 'about', 'my', 'mistakes', 'and', 'good', 'coding', 'practices', 'that', 'i', 'should', 'follow', 'There', 'fore', 'i', 'think', 'it', 'would', 'be', 'great', 'if', 'we', 'can', 'discuss', 'more', 'examples', 'in', 'the', 'class', 'madam', 'explained', 'the', 'oop', 'concepts', 'clearly', 'with', 'examples', 'lectures', 'were', 'interesting', 'we', 'want', 'more', 'scenario', 'examples', 'and', 'answers', 'with', 'explanations', 'in', 'future', 'I', 'satisfy', 'about', 'first', 'lectures', 'That', 'way', 'of', 'teaching', 'is', 'really', 'good', 'for', 'coming', 'lectures', 'too', 'lectuers', 'are', 'very', 'good', 'take', 'good', 'effort', 'to', 'make', 'undersatand', 'every', 'student', 'in', 'the', 'room', 'very', 'helpfull', 'I', 'was', 'able', 'to', 'obtain', 'a', 'clear', 'picture', 'about', 'OOP', 'and', 'its', 'concepts', 'lecture', 'slides', 'explanations', 'were', 'very', 'clear', 'it', 's', 'very', 'good', 'to', 'letting', 'ask', 'questions', 'and', 'explain', 'again', 'with', 'suitable', 'examples', 'sometimes', 'some', 'codes', 'on', 'white', 'board', 'were', 'unclear', 'at', 'the', 'back', 'overall', 'very', 'good', 'The', 'lectures', 'were', 'good', 'and', 'clear', 'And', 'they', 'weren', 't', 'too', 'fast', 'Writing', 'code', 'was', 'somewhat', 'confusing', 'because', 'I', 'didn', 't', 'know', 'java', 'before', 'Actually', 'teaching', 'is', 'very', 'good', 'and', 'can', 'understand', 'easily', 'the', 'concepts', 'by', 'examples', 'which', 'are', 'given', 'in', 'the', 'class', 'it', 'will', 'be', 'more', 'helpful', 'if', 'provide', 'solved', 'questions', 'as', 'well', 'thankyou']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBwo5De-k9F_"
      },
      "source": [
        "from gensim.utils import tokenize\n",
        "tokenize_text_gensim = tokenize(text)\n",
        "tokens = list(tokenize(raw))\n",
        "with open('/content/student_course_out_tokenize.txt', 'w') as writefile:\n",
        "    writefile.write(str(tokens))\n"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHjXXDy4oH0B"
      },
      "source": [
        "# spell corrections"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7McP9fnPoPnm"
      },
      "source": [
        "**isolated word correction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1PNTpk6Rg4n",
        "outputId": "e8089f15-f54f-493b-b130-8dadb38d175b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pip install pyspellchecker"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspellchecker\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/96/827c132397d0eb5731c1eda05dbfb019ede064ca8c7d0f329160ce0a4acd/pyspellchecker-0.5.5-py2.py3-none-any.whl (1.9MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9MB 2.9MB/s \n",
            "\u001b[?25hInstalling collected packages: pyspellchecker\n",
            "Successfully installed pyspellchecker-0.5.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMA-tbYP-3K4"
      },
      "source": [
        "from spellchecker import SpellChecker\n",
        "\n",
        "spell = SpellChecker()\n",
        "def correct_spellings(text):\n",
        "    text = text\n",
        "    corrected_text = []\n",
        "    misspelled_words = spell.unknown(text.split())\n",
        "    for word in text.split():\n",
        "        if word in misspelled_words:\n",
        "            corrected_text.append(text + '  -->was changes as -->'+ spell.correction(word))\n",
        "        else:\n",
        "            continue\n",
        "    return \" \".join(corrected_text)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cU1QAx5xRxPf",
        "outputId": "0c8262df-6351-4796-e41f-a35e893be9ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tokens = list(tokenize(raw))\n",
        "\n",
        "l=[]\n",
        "for word in tokens:\n",
        "    l.append(correct_spellings(word))\n",
        "spel_changed_words_list = [i for i in l if i] \n",
        "spel_changed_words_list"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['exercisers  -->was changes as -->exercises',\n",
              " 'lectuers  -->was changes as -->lectures',\n",
              " 'undersatand  -->was changes as -->understand',\n",
              " 'helpfull  -->was changes as -->helpful',\n",
              " 'weren  -->was changes as -->were']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36mMyi6eoVUO"
      },
      "source": [
        "**context sensitive word correction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8A4QSakjcMX",
        "outputId": "07a20c4a-af1d-4803-e195-6ad71ace415c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pip install symspellpy"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting symspellpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/af/e71fcca6a42b6a63f518b0c1627e1f67822815cb0cf71e6af05acbd75c78/symspellpy-6.7.0-py3-none-any.whl (2.6MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6MB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.1 in /usr/local/lib/python3.6/dist-packages (from symspellpy) (1.18.5)\n",
            "Installing collected packages: symspellpy\n",
            "Successfully installed symspellpy-6.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TJbTZ3TjYhI",
        "outputId": "1ad8b94c-564e-429e-9509-b882b177487e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from symspellpy.symspellpy import SymSpell, Verbosity\n",
        "word_length = 2\n",
        "prefix_length = 7\n",
        "sym_spell = SymSpell(word_length, prefix_length)\n",
        "print(\"Corpus file not found\") if not sym_spell.create_dictionary(\"/content/big.txt\") else print(\"Success!\")\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Success!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4E93UDMjCyw"
      },
      "source": [
        "preview = 10\n",
        "def correct_tocknized_text(words):\n",
        "    corr_count = 0\n",
        "    corrected_words = []\n",
        "    for i, word in enumerate(words[:-word_length+1]):\n",
        "        word_set = [words[i+j] for j in range(word_length)]\n",
        "        _input = ' '.join(word_set)\n",
        "        result = sym_spell.word_segmentation(_input)\n",
        "        correction = result.corrected_string\n",
        "        if correction.lower() != _input.lower() and preview < corr_count:\n",
        "            corr_count += 1\n",
        "            print('\"{}\" is corrected as \"{}\"'.format(_input, correction))\n",
        "        corrected_words.append(correction.split(' ')[0])\n",
        "    corrected_words.append(correction.split(' ')[1])\n",
        "    return corrected_words"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpQLOFZhjFLH",
        "outputId": "bcc8eb61-6a65-4af2-d175-b6d852e3f2f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(correct_tocknized_text(list(tokenize(raw))))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Honestly', 'last', 'seven', 'lectures', 'are', 'good', 'Lectures', 'are', 'understandable', 'Lecture', 'sides', 'are', 'very', 'useful', 'to', 'self', 'study', 'also', 'The', 'given', 'opportunity', 'to', 'ask', 'questions', 'from', 'the', 'lecturer', 'is', 'appreciative', 'Good', 'please', 'do', 'reap', 'at', 'class', 'starting', 'it', 's', 'better', 'for', 'us', 'sometimes', 'teaching', 'speed', 'is', 'very', 'high', 'Thanks', 'The', 'lectures', 'are', 'good', 'but', 'a', 'bit', 'speed', 'A', 'in', 'class', 'working', 'activity', 'is', 'a', 'must', 'one', 'So', 'please', 'take', 'another', 'hour', 'in', 'thursdays', 'madame', 'We', 'can', 'hear', 'your', 'voice', 'clearly', 'and', 'can', 'understand', 'the', 'things', 'you', 'teach', 'Presentation', 'sides', 'also', 'good', 'source', 'to', 'refer', 'of', 'you', 'can', 'do', 'more', 'example', 'questions', 'within', 'the', 'classroom', 'and', 'it', 'will', 'help', 'us', 'to', 'understand', 'the', 'principles', 'well', 'Lectures', 'was', 'well', 'structures', 'and', 'well', 'organized', 'It', 'was', 'easy', 'to', 'understand', 'Lecture', 'sides', 'and', 'laws', 'were', 'also', 'well', 'organized', 'Lectures', 'were', 'good', 'understandable', 'The', 'lecture', 'sides', 'were', 'well', 'organized', 'and', 'the', 'examples', 'done', 'in', 'the', 'class', 'helped', 'a', 'lot', 'to', 'learn', 'this', 'new', 'language', 'and', 'also', 'the', 'principles', 'of', 'Top', 'Motivate', 'to', 'well', 'Would', 'have', 'been', 'better', 'if', 'we', 'discussed', 'more', 'about', 'the', 'solutions', 'of', 'coming', 'exercises', 'I', 'think', 'i', 'learned', 'a', 'lot', 'from', 'the', 'codes', 'you', 'write', 'in', 'the', 'board', 'When', 'i', 'compare', 'my', 'codes', 'with', 'yours', 'i', 'can', 'learn', 'about', 'my', 'mistakes', 'and', 'good', 'coming', 'practices', 'that', 'i', 'should', 'follow', 'There', 'fore', 'i', 'think', 'it', 'would', 'be', 'great', 'if', 'we', 'can', 'discuss', 'more', 'examples', 'in', 'the', 'class', 'madam', 'explained', 'the', 'top', 'concepts', 'clearly', 'with', 'examples', 'lectures', 'were', 'interesting', 'we', 'want', 'more', 'scenario', 'examples', 'and', 'answers', 'with', 'explanations', 'in', 'future', 'I', 'satisfy', 'about', 'first', 'lectures', 'That', 'way', 'of', 'teaching', 'is', 'really', 'good', 'for', 'coming', 'lectures', 'too', 'lectures', 'are', 'very', 'good', 'take', 'good', 'effort', 'to', 'make', 'understand', 'every', 'student', 'in', 'the', 'room', 'very', 'helpful', 'I', 'was', 'able', 'to', 'obtain', 'a', 'clear', 'picture', 'about', 'Top', 'and', 'its', 'concepts', 'lecture', 'sides', 'explanations', 'were', 'very', 'clear', 'it', 's', 'very', 'good', 'to', 'letting', 'ask', 'questions', 'and', 'explain', 'again', 'with', 'suitable', 'examples', 'sometimes', 'some', 'codes', 'on', 'white', 'board', 'were', 'unclear', 'at', 'the', 'back', 'overall', 'very', 'good', 'The', 'lectures', 'were', 'good', 'and', 'clear', 'And', 'they', 'were', 't', 'too', 'fast', 'Writing', 'code', 'was', 'somewhat', 'confusing', 'because', 'I', 'did', 't', 'know', 'cava', 'before', 'Actually', 'teaching', 'is', 'very', 'good', 'and', 'can', 'understand', 'easily', 'the', 'concepts', 'by', 'examples', 'which', 'are', 'given', 'in', 'the', 'class', 'it', 'will', 'be', 'more', 'helpful', 'if', 'provide', 'solved', 'questions', 'as', 'well', 'thank']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVg8glUJobV6"
      },
      "source": [
        "# stemmer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KU_mkk3b_gt5",
        "outputId": "c56df829-5575-46b3-fcbc-918451f7f41d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from nltk.stem.snowball import SnowballStemmer\n",
        "tokens = list(tokenize(raw))\n",
        "stemmer = SnowballStemmer(language='english')\n",
        "\n",
        "for token in tokens:\n",
        "    print(token + ' --> ' + stemmer.stem(token))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Honestly --> honest\n",
            "last --> last\n",
            "seven --> seven\n",
            "lectures --> lectur\n",
            "are --> are\n",
            "good --> good\n",
            "Lectures --> lectur\n",
            "are --> are\n",
            "understandable --> understand\n",
            "Lecture --> lectur\n",
            "slides --> slide\n",
            "are --> are\n",
            "very --> veri\n",
            "useful --> use\n",
            "to --> to\n",
            "self --> self\n",
            "study --> studi\n",
            "also --> also\n",
            "The --> the\n",
            "given --> given\n",
            "opportunity --> opportun\n",
            "to --> to\n",
            "ask --> ask\n",
            "questions --> question\n",
            "from --> from\n",
            "the --> the\n",
            "lecturer --> lectur\n",
            "is --> is\n",
            "appreciative --> appreci\n",
            "Good --> good\n",
            "please --> pleas\n",
            "do --> do\n",
            "recap --> recap\n",
            "at --> at\n",
            "class --> class\n",
            "starting --> start\n",
            "it --> it\n",
            "s --> s\n",
            "better --> better\n",
            "for --> for\n",
            "us --> us\n",
            "sometimes --> sometim\n",
            "teaching --> teach\n",
            "speed --> speed\n",
            "is --> is\n",
            "very --> veri\n",
            "high --> high\n",
            "Thanks --> thank\n",
            "The --> the\n",
            "lectures --> lectur\n",
            "are --> are\n",
            "good --> good\n",
            "but --> but\n",
            "a --> a\n",
            "bit --> bit\n",
            "speed --> speed\n",
            "A --> a\n",
            "in --> in\n",
            "class --> class\n",
            "working --> work\n",
            "activity --> activ\n",
            "is --> is\n",
            "a --> a\n",
            "must --> must\n",
            "one --> one\n",
            "So --> so\n",
            "please --> pleas\n",
            "take --> take\n",
            "another --> anoth\n",
            "hour --> hour\n",
            "in --> in\n",
            "thursdays --> thursday\n",
            "madame --> madam\n",
            "We --> we\n",
            "can --> can\n",
            "hear --> hear\n",
            "your --> your\n",
            "voice --> voic\n",
            "clearly --> clear\n",
            "and --> and\n",
            "can --> can\n",
            "understand --> understand\n",
            "the --> the\n",
            "things --> thing\n",
            "you --> you\n",
            "teach --> teach\n",
            "Presentation --> present\n",
            "slides --> slide\n",
            "also --> also\n",
            "good --> good\n",
            "source --> sourc\n",
            "to --> to\n",
            "refer --> refer\n",
            "lf --> lf\n",
            "you --> you\n",
            "can --> can\n",
            "do --> do\n",
            "more --> more\n",
            "example --> exampl\n",
            "questions --> question\n",
            "within --> within\n",
            "the --> the\n",
            "classroom --> classroom\n",
            "and --> and\n",
            "it --> it\n",
            "will --> will\n",
            "help --> help\n",
            "us --> us\n",
            "to --> to\n",
            "understand --> understand\n",
            "the --> the\n",
            "principles --> principl\n",
            "well --> well\n",
            "Lectures --> lectur\n",
            "was --> was\n",
            "well --> well\n",
            "structured --> structur\n",
            "and --> and\n",
            "well --> well\n",
            "organized --> organ\n",
            "It --> it\n",
            "was --> was\n",
            "easy --> easi\n",
            "to --> to\n",
            "understand --> understand\n",
            "Lecture --> lectur\n",
            "slides --> slide\n",
            "and --> and\n",
            "labs --> lab\n",
            "were --> were\n",
            "also --> also\n",
            "well --> well\n",
            "organized --> organ\n",
            "Lectures --> lectur\n",
            "were --> were\n",
            "good --> good\n",
            "understandable --> understand\n",
            "The --> the\n",
            "lecture --> lectur\n",
            "slides --> slide\n",
            "were --> were\n",
            "well --> well\n",
            "organized --> organ\n",
            "and --> and\n",
            "the --> the\n",
            "examples --> exampl\n",
            "done --> done\n",
            "in --> in\n",
            "the --> the\n",
            "class --> class\n",
            "helped --> help\n",
            "a --> a\n",
            "lot --> lot\n",
            "to --> to\n",
            "learn --> learn\n",
            "this --> this\n",
            "new --> new\n",
            "language --> languag\n",
            "and --> and\n",
            "also --> also\n",
            "the --> the\n",
            "principles --> principl\n",
            "of --> of\n",
            "OOP --> oop\n",
            "Motivated --> motiv\n",
            "to --> to\n",
            "well --> well\n",
            "Would --> would\n",
            "have --> have\n",
            "been --> been\n",
            "better --> better\n",
            "if --> if\n",
            "we --> we\n",
            "discussed --> discuss\n",
            "more --> more\n",
            "about --> about\n",
            "the --> the\n",
            "solutions --> solut\n",
            "of --> of\n",
            "coding --> code\n",
            "exercisers --> exercis\n",
            "I --> i\n",
            "think --> think\n",
            "i --> i\n",
            "learned --> learn\n",
            "a --> a\n",
            "lot --> lot\n",
            "from --> from\n",
            "the --> the\n",
            "codes --> code\n",
            "you --> you\n",
            "write --> write\n",
            "in --> in\n",
            "the --> the\n",
            "board --> board\n",
            "When --> when\n",
            "i --> i\n",
            "compare --> compar\n",
            "my --> my\n",
            "codes --> code\n",
            "with --> with\n",
            "yours --> your\n",
            "i --> i\n",
            "can --> can\n",
            "learn --> learn\n",
            "about --> about\n",
            "my --> my\n",
            "mistakes --> mistak\n",
            "and --> and\n",
            "good --> good\n",
            "coding --> code\n",
            "practices --> practic\n",
            "that --> that\n",
            "i --> i\n",
            "should --> should\n",
            "follow --> follow\n",
            "There --> there\n",
            "fore --> fore\n",
            "i --> i\n",
            "think --> think\n",
            "it --> it\n",
            "would --> would\n",
            "be --> be\n",
            "great --> great\n",
            "if --> if\n",
            "we --> we\n",
            "can --> can\n",
            "discuss --> discuss\n",
            "more --> more\n",
            "examples --> exampl\n",
            "in --> in\n",
            "the --> the\n",
            "class --> class\n",
            "madam --> madam\n",
            "explained --> explain\n",
            "the --> the\n",
            "oop --> oop\n",
            "concepts --> concept\n",
            "clearly --> clear\n",
            "with --> with\n",
            "examples --> exampl\n",
            "lectures --> lectur\n",
            "were --> were\n",
            "interesting --> interest\n",
            "we --> we\n",
            "want --> want\n",
            "more --> more\n",
            "scenario --> scenario\n",
            "examples --> exampl\n",
            "and --> and\n",
            "answers --> answer\n",
            "with --> with\n",
            "explanations --> explan\n",
            "in --> in\n",
            "future --> futur\n",
            "I --> i\n",
            "satisfy --> satisfi\n",
            "about --> about\n",
            "first --> first\n",
            "lectures --> lectur\n",
            "That --> that\n",
            "way --> way\n",
            "of --> of\n",
            "teaching --> teach\n",
            "is --> is\n",
            "really --> realli\n",
            "good --> good\n",
            "for --> for\n",
            "coming --> come\n",
            "lectures --> lectur\n",
            "too --> too\n",
            "lectuers --> lectuer\n",
            "are --> are\n",
            "very --> veri\n",
            "good --> good\n",
            "take --> take\n",
            "good --> good\n",
            "effort --> effort\n",
            "to --> to\n",
            "make --> make\n",
            "undersatand --> undersatand\n",
            "every --> everi\n",
            "student --> student\n",
            "in --> in\n",
            "the --> the\n",
            "room --> room\n",
            "very --> veri\n",
            "helpfull --> helpful\n",
            "I --> i\n",
            "was --> was\n",
            "able --> abl\n",
            "to --> to\n",
            "obtain --> obtain\n",
            "a --> a\n",
            "clear --> clear\n",
            "picture --> pictur\n",
            "about --> about\n",
            "OOP --> oop\n",
            "and --> and\n",
            "its --> it\n",
            "concepts --> concept\n",
            "lecture --> lectur\n",
            "slides --> slide\n",
            "explanations --> explan\n",
            "were --> were\n",
            "very --> veri\n",
            "clear --> clear\n",
            "it --> it\n",
            "s --> s\n",
            "very --> veri\n",
            "good --> good\n",
            "to --> to\n",
            "letting --> let\n",
            "ask --> ask\n",
            "questions --> question\n",
            "and --> and\n",
            "explain --> explain\n",
            "again --> again\n",
            "with --> with\n",
            "suitable --> suitabl\n",
            "examples --> exampl\n",
            "sometimes --> sometim\n",
            "some --> some\n",
            "codes --> code\n",
            "on --> on\n",
            "white --> white\n",
            "board --> board\n",
            "were --> were\n",
            "unclear --> unclear\n",
            "at --> at\n",
            "the --> the\n",
            "back --> back\n",
            "overall --> overal\n",
            "very --> veri\n",
            "good --> good\n",
            "The --> the\n",
            "lectures --> lectur\n",
            "were --> were\n",
            "good --> good\n",
            "and --> and\n",
            "clear --> clear\n",
            "And --> and\n",
            "they --> they\n",
            "weren --> weren\n",
            "t --> t\n",
            "too --> too\n",
            "fast --> fast\n",
            "Writing --> write\n",
            "code --> code\n",
            "was --> was\n",
            "somewhat --> somewhat\n",
            "confusing --> confus\n",
            "because --> becaus\n",
            "I --> i\n",
            "didn --> didn\n",
            "t --> t\n",
            "know --> know\n",
            "java --> java\n",
            "before --> befor\n",
            "Actually --> actual\n",
            "teaching --> teach\n",
            "is --> is\n",
            "very --> veri\n",
            "good --> good\n",
            "and --> and\n",
            "can --> can\n",
            "understand --> understand\n",
            "easily --> easili\n",
            "the --> the\n",
            "concepts --> concept\n",
            "by --> by\n",
            "examples --> exampl\n",
            "which --> which\n",
            "are --> are\n",
            "given --> given\n",
            "in --> in\n",
            "the --> the\n",
            "class --> class\n",
            "it --> it\n",
            "will --> will\n",
            "be --> be\n",
            "more --> more\n",
            "helpful --> help\n",
            "if --> if\n",
            "provide --> provid\n",
            "solved --> solv\n",
            "questions --> question\n",
            "as --> as\n",
            "well --> well\n",
            "thankyou --> thankyou\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4eoaPA6lVVs"
      },
      "source": [
        "from gensim.utils import tokenize\n",
        "tokenize_text_gensim = tokenize(text)\n",
        "tokens = list(tokenize(raw))\n",
        "with open('/content/student_course_out_stem.txt', 'w') as writefile:\n",
        "    for token in tokens:\n",
        "      writefile.write(str(token + ' --> ' + stemmer.stem(token)))"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbiuQc94oe-F"
      },
      "source": [
        "# lemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdDxUAGE_5tM"
      },
      "source": [
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIajrZ5I_uDj",
        "outputId": "b5bf3244-b7f4-45ff-db40-c3b97b699a1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "tokens = list(tokenize(raw))\n",
        "for token in tokens:\n",
        "    print(token + ' --> ' + lemmatizer.lemmatize(token))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Honestly --> Honestly\n",
            "last --> last\n",
            "seven --> seven\n",
            "lectures --> lecture\n",
            "are --> are\n",
            "good --> good\n",
            "Lectures --> Lectures\n",
            "are --> are\n",
            "understandable --> understandable\n",
            "Lecture --> Lecture\n",
            "slides --> slide\n",
            "are --> are\n",
            "very --> very\n",
            "useful --> useful\n",
            "to --> to\n",
            "self --> self\n",
            "study --> study\n",
            "also --> also\n",
            "The --> The\n",
            "given --> given\n",
            "opportunity --> opportunity\n",
            "to --> to\n",
            "ask --> ask\n",
            "questions --> question\n",
            "from --> from\n",
            "the --> the\n",
            "lecturer --> lecturer\n",
            "is --> is\n",
            "appreciative --> appreciative\n",
            "Good --> Good\n",
            "please --> please\n",
            "do --> do\n",
            "recap --> recap\n",
            "at --> at\n",
            "class --> class\n",
            "starting --> starting\n",
            "it --> it\n",
            "s --> s\n",
            "better --> better\n",
            "for --> for\n",
            "us --> u\n",
            "sometimes --> sometimes\n",
            "teaching --> teaching\n",
            "speed --> speed\n",
            "is --> is\n",
            "very --> very\n",
            "high --> high\n",
            "Thanks --> Thanks\n",
            "The --> The\n",
            "lectures --> lecture\n",
            "are --> are\n",
            "good --> good\n",
            "but --> but\n",
            "a --> a\n",
            "bit --> bit\n",
            "speed --> speed\n",
            "A --> A\n",
            "in --> in\n",
            "class --> class\n",
            "working --> working\n",
            "activity --> activity\n",
            "is --> is\n",
            "a --> a\n",
            "must --> must\n",
            "one --> one\n",
            "So --> So\n",
            "please --> please\n",
            "take --> take\n",
            "another --> another\n",
            "hour --> hour\n",
            "in --> in\n",
            "thursdays --> thursday\n",
            "madame --> madame\n",
            "We --> We\n",
            "can --> can\n",
            "hear --> hear\n",
            "your --> your\n",
            "voice --> voice\n",
            "clearly --> clearly\n",
            "and --> and\n",
            "can --> can\n",
            "understand --> understand\n",
            "the --> the\n",
            "things --> thing\n",
            "you --> you\n",
            "teach --> teach\n",
            "Presentation --> Presentation\n",
            "slides --> slide\n",
            "also --> also\n",
            "good --> good\n",
            "source --> source\n",
            "to --> to\n",
            "refer --> refer\n",
            "lf --> lf\n",
            "you --> you\n",
            "can --> can\n",
            "do --> do\n",
            "more --> more\n",
            "example --> example\n",
            "questions --> question\n",
            "within --> within\n",
            "the --> the\n",
            "classroom --> classroom\n",
            "and --> and\n",
            "it --> it\n",
            "will --> will\n",
            "help --> help\n",
            "us --> u\n",
            "to --> to\n",
            "understand --> understand\n",
            "the --> the\n",
            "principles --> principle\n",
            "well --> well\n",
            "Lectures --> Lectures\n",
            "was --> wa\n",
            "well --> well\n",
            "structured --> structured\n",
            "and --> and\n",
            "well --> well\n",
            "organized --> organized\n",
            "It --> It\n",
            "was --> wa\n",
            "easy --> easy\n",
            "to --> to\n",
            "understand --> understand\n",
            "Lecture --> Lecture\n",
            "slides --> slide\n",
            "and --> and\n",
            "labs --> lab\n",
            "were --> were\n",
            "also --> also\n",
            "well --> well\n",
            "organized --> organized\n",
            "Lectures --> Lectures\n",
            "were --> were\n",
            "good --> good\n",
            "understandable --> understandable\n",
            "The --> The\n",
            "lecture --> lecture\n",
            "slides --> slide\n",
            "were --> were\n",
            "well --> well\n",
            "organized --> organized\n",
            "and --> and\n",
            "the --> the\n",
            "examples --> example\n",
            "done --> done\n",
            "in --> in\n",
            "the --> the\n",
            "class --> class\n",
            "helped --> helped\n",
            "a --> a\n",
            "lot --> lot\n",
            "to --> to\n",
            "learn --> learn\n",
            "this --> this\n",
            "new --> new\n",
            "language --> language\n",
            "and --> and\n",
            "also --> also\n",
            "the --> the\n",
            "principles --> principle\n",
            "of --> of\n",
            "OOP --> OOP\n",
            "Motivated --> Motivated\n",
            "to --> to\n",
            "well --> well\n",
            "Would --> Would\n",
            "have --> have\n",
            "been --> been\n",
            "better --> better\n",
            "if --> if\n",
            "we --> we\n",
            "discussed --> discussed\n",
            "more --> more\n",
            "about --> about\n",
            "the --> the\n",
            "solutions --> solution\n",
            "of --> of\n",
            "coding --> coding\n",
            "exercisers --> exerciser\n",
            "I --> I\n",
            "think --> think\n",
            "i --> i\n",
            "learned --> learned\n",
            "a --> a\n",
            "lot --> lot\n",
            "from --> from\n",
            "the --> the\n",
            "codes --> code\n",
            "you --> you\n",
            "write --> write\n",
            "in --> in\n",
            "the --> the\n",
            "board --> board\n",
            "When --> When\n",
            "i --> i\n",
            "compare --> compare\n",
            "my --> my\n",
            "codes --> code\n",
            "with --> with\n",
            "yours --> yours\n",
            "i --> i\n",
            "can --> can\n",
            "learn --> learn\n",
            "about --> about\n",
            "my --> my\n",
            "mistakes --> mistake\n",
            "and --> and\n",
            "good --> good\n",
            "coding --> coding\n",
            "practices --> practice\n",
            "that --> that\n",
            "i --> i\n",
            "should --> should\n",
            "follow --> follow\n",
            "There --> There\n",
            "fore --> fore\n",
            "i --> i\n",
            "think --> think\n",
            "it --> it\n",
            "would --> would\n",
            "be --> be\n",
            "great --> great\n",
            "if --> if\n",
            "we --> we\n",
            "can --> can\n",
            "discuss --> discus\n",
            "more --> more\n",
            "examples --> example\n",
            "in --> in\n",
            "the --> the\n",
            "class --> class\n",
            "madam --> madam\n",
            "explained --> explained\n",
            "the --> the\n",
            "oop --> oop\n",
            "concepts --> concept\n",
            "clearly --> clearly\n",
            "with --> with\n",
            "examples --> example\n",
            "lectures --> lecture\n",
            "were --> were\n",
            "interesting --> interesting\n",
            "we --> we\n",
            "want --> want\n",
            "more --> more\n",
            "scenario --> scenario\n",
            "examples --> example\n",
            "and --> and\n",
            "answers --> answer\n",
            "with --> with\n",
            "explanations --> explanation\n",
            "in --> in\n",
            "future --> future\n",
            "I --> I\n",
            "satisfy --> satisfy\n",
            "about --> about\n",
            "first --> first\n",
            "lectures --> lecture\n",
            "That --> That\n",
            "way --> way\n",
            "of --> of\n",
            "teaching --> teaching\n",
            "is --> is\n",
            "really --> really\n",
            "good --> good\n",
            "for --> for\n",
            "coming --> coming\n",
            "lectures --> lecture\n",
            "too --> too\n",
            "lectuers --> lectuers\n",
            "are --> are\n",
            "very --> very\n",
            "good --> good\n",
            "take --> take\n",
            "good --> good\n",
            "effort --> effort\n",
            "to --> to\n",
            "make --> make\n",
            "undersatand --> undersatand\n",
            "every --> every\n",
            "student --> student\n",
            "in --> in\n",
            "the --> the\n",
            "room --> room\n",
            "very --> very\n",
            "helpfull --> helpfull\n",
            "I --> I\n",
            "was --> wa\n",
            "able --> able\n",
            "to --> to\n",
            "obtain --> obtain\n",
            "a --> a\n",
            "clear --> clear\n",
            "picture --> picture\n",
            "about --> about\n",
            "OOP --> OOP\n",
            "and --> and\n",
            "its --> it\n",
            "concepts --> concept\n",
            "lecture --> lecture\n",
            "slides --> slide\n",
            "explanations --> explanation\n",
            "were --> were\n",
            "very --> very\n",
            "clear --> clear\n",
            "it --> it\n",
            "s --> s\n",
            "very --> very\n",
            "good --> good\n",
            "to --> to\n",
            "letting --> letting\n",
            "ask --> ask\n",
            "questions --> question\n",
            "and --> and\n",
            "explain --> explain\n",
            "again --> again\n",
            "with --> with\n",
            "suitable --> suitable\n",
            "examples --> example\n",
            "sometimes --> sometimes\n",
            "some --> some\n",
            "codes --> code\n",
            "on --> on\n",
            "white --> white\n",
            "board --> board\n",
            "were --> were\n",
            "unclear --> unclear\n",
            "at --> at\n",
            "the --> the\n",
            "back --> back\n",
            "overall --> overall\n",
            "very --> very\n",
            "good --> good\n",
            "The --> The\n",
            "lectures --> lecture\n",
            "were --> were\n",
            "good --> good\n",
            "and --> and\n",
            "clear --> clear\n",
            "And --> And\n",
            "they --> they\n",
            "weren --> weren\n",
            "t --> t\n",
            "too --> too\n",
            "fast --> fast\n",
            "Writing --> Writing\n",
            "code --> code\n",
            "was --> wa\n",
            "somewhat --> somewhat\n",
            "confusing --> confusing\n",
            "because --> because\n",
            "I --> I\n",
            "didn --> didn\n",
            "t --> t\n",
            "know --> know\n",
            "java --> java\n",
            "before --> before\n",
            "Actually --> Actually\n",
            "teaching --> teaching\n",
            "is --> is\n",
            "very --> very\n",
            "good --> good\n",
            "and --> and\n",
            "can --> can\n",
            "understand --> understand\n",
            "easily --> easily\n",
            "the --> the\n",
            "concepts --> concept\n",
            "by --> by\n",
            "examples --> example\n",
            "which --> which\n",
            "are --> are\n",
            "given --> given\n",
            "in --> in\n",
            "the --> the\n",
            "class --> class\n",
            "it --> it\n",
            "will --> will\n",
            "be --> be\n",
            "more --> more\n",
            "helpful --> helpful\n",
            "if --> if\n",
            "provide --> provide\n",
            "solved --> solved\n",
            "questions --> question\n",
            "as --> a\n",
            "well --> well\n",
            "thankyou --> thankyou\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOttMAY1lkrK"
      },
      "source": [
        "from gensim.utils import tokenize\n",
        "tokenize_text_gensim = tokenize(text)\n",
        "tokens = list(tokenize(raw))\n",
        "with open('/content/studet_course_out_lematize.txt', 'w') as writefile:\n",
        "    for token in tokens:\n",
        "      writefile.write(str(token + ' --> ' + lemmatizer.lemmatize(token)))"
      ],
      "execution_count": 49,
      "outputs": []
    }
  ]
}